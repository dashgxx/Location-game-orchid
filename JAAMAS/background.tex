\section{Background}
In this section we discuss related work and provide a short background on the techniques used in this paper.  As our work lies at the intersection between Multi-Agent Coordination and Human-Computer Interaction (HCI) for disaster management applications, we discuss relevant algorithms for multi-agent coordination to support emergency responders and then describe the HCI techniques and approaches for the same purpose. We then go on to discuss the challenges relevant to human-agent collaboration and then justify our use of mixed-reality games to evaluate this form of collaboration.  Through our analysis we also identify the challenges that pertain to the coordination of human emergency responders under significant uncertainty and therefore, conclude with some background on decision-theoretic approaches to solving the coordination problem under uncertainty.



\subsection{Human Team Coordination for Disaster Response}
Team coordination focuses on managing interdependencies between activities performed  by individual team members to achieve the team's goal \cite[p. 361]{Malone:1990}. In emergency response failures in team coordination can often occur due to the complexities of such interdependencies, and such failures are widely acknowledged as the most significant factor that can cost human lives \cite[p. 2]{Toups et al., 2011}. In particular, related work studies the challenges that arise when team members aim to create a shared understanding (e.g., of what needs to be done) \cite{Convertino2010}, develop situation awareness (i.e., knowledge of the environment and the actors within it), and align cooperative action through on-going communication.  

Moreover, we note the work of \cite{chen:Etal:2005} that highlighted that one important characteristic of large-scale disasters is the presence of multiple spatially distributed incidents. To deal with multiple incidents, the disaster response team has to coordinate spatially distributed resources and personnel to carry out operations (e.g. search, rescue, and evacuation). Therefore, it is necessary to optimise the coordination of teams by allocating tasks to teams in time and space efficiently and sufficiently \cite{Nourjou et al 2011}. Thus, a number of tools and system architectures have been developed to support such team coordination (Monares, 2011, Padilha, 2010, Convertino et al. 2011). However, while these approaches focus on providing tools to human teams, a number of agent-based solutions have been developed in the last few years to better guide human emergency responders. We elaborate on such solutions next.
\

\subsection{Agents for Disaster Response}\label{sec:agents disasters}
Kitano et al \cite{kitano:2001} were the first to propose disaster response as a key application area for multi-agent systems. Since then, a number of algorithms and simulation platforms have been developed to solve the computational challenges involved. For example, algorithms  have been developed to efficiently allocate emergency responders to rescue tasks (e.g., to rescue civilians, extinguish fires, or unblock roads) for (i) decentralised coordination: where emergency responders need to chose their actions based on local knowledge \cite{Chapman2009,puyol:etal:2014}, (ii)  coordination by a central authority: where a command centre is able to choose actions for all the members of the team given complete knowledge of the system \cite{koes2006constraint,Scerri2005,Khan-2011-JAAMAS} , and (iii) coalition formation: where sub-teams can perform tasks with different levels of efficiency, as defined by the synergies between their capabilities (e.g., when two policemen help rescue a civilian from rubble they would be less effective than a fire and rescue officer and a medic) \cite{ramchurn:etal}. Many of these algorithms are actually evaluated in simulation using the the RoboCupRescue disaster simulation platform \cite{skinner:ramchurn:2010}. In this platform, emergency response tasks are modelled computationally (e.g., functions describing speed and efficiency of agents at completing tasks) and the emergency responders are modelled as agents that automatically implement the outputs of a given task allocation algorithm \cite{kleiner:etal:2013,ramchurn:etal:2010}. While such evaluations are useful to determine extreme scenarios (e.g., best case when all agents implement all tasks perfectly or worst case when they do not), they are prone to misrepresentations of human decision making. Hence, we next discuss approaches to human teaming in disaster response.


\subsection{Challenges for Human Agent Collaboration}
Many multi-agent agent coordination algorithms have potential to be applied to support task assignment of responder teams. However, before we use those algorithms to build agent planning support system, there is a need to understand how human and agent can effectively collaborate.  Human factors researchers have conducted controlled experiments to identify key aspects of human agent collaboration \cite{Bradshaw 2011, Cooke2007 ,Sukthankar2009, Wagner2004} and evaluate strategies of agent support for teams \cite{Lenox1998,Lenox2000,(Nourjou et al 2011) }. Prior research has recognised that interaction design is vital for the performance of socio-technical human-agent systems \cite{Murthy1997}, particularly where an agent directly instructs humans \cite{S. Moran2013}. With inappropriate interaction design, agent-based planning support may function inefficiently, or at worst, hinder the performance of human teams. Although there is much literature in planning support, task assignment, and human-agent collaboration, Yet, real world studies of how human teams handle agent support are rare. \\

Moverover, \cite{Bowers1994} have shown that an ill-designed work-flow management/automation system can lead to undesirable results, not only fail to improve work efficiency but also hinders human performance. Bowers et al. found that extreme difficulties might be encountered when introducing new technology support for human teams. It turns out that new technologies might not support, but  disrupt smooth workflow if they are designed in an organisationally unacceptable way \cite{Abbott1994}. We believe the same is true for intelligent planning support. Before we can build intelligent systems that support human team coordination, we believe it is crucial to run field trials to understand the potential impact of technology support for team coordination (as we show in this paper -- see Section \ref{xx}). In particular, in this work, we turn to the use of gamification to run such trials. \\

\subsection{Disaster Simulation and Games }
Computational simulations, particularly agent-based simulations, are the predominant approach in the computing literature to predict the consequences of certain courses of action in disasters \cite{Hawe et al., 2012}, to model information flow among first responders \cite{Robinson and Brown, 2005}, or to model the logistic distribution of emergency relief supplies \cite{Lee et al., 2007}.\\

The limitations of computational simulations are manifold. For example, Simonovic highlights that simulations may rely on unrealistic geographical topography, and most importantly, may not "account for human psychosocial characteristics and individual movement, and (...) learning ability" \cite{Simonovic, 2009: 89}. The impact of emotional and physical responses likely in a disaster, such as stress, fear, exertion or panic \cite{Drury et al., 2009} remains understudied in approaches that rely purely on computational simulation.\\

In our study, we adopt a serious mixed-reality game approach to provide a setting in which people experience realistic cognitive and physical stress \cite{Fischer:etal:2012}. Mixed-reality games are recreational experiences that make use of pervasive technologies such as smart phones, wireless technologies and sensors with the aim of blending game events into a real world environment \cite{???} \todo{add ref: Benford, S., Magerkurth, C., Ljungstrand, P.: Bridging the physical and digital in pervasive gam- ing. CACM 48(3) (March 2005), 54?57.}. Arguably, they have become an established vehicle to explore socio-technical issues in complex real world settings \cite{XXX} \todo{add ref: Crabtree, A., Benford, S., Greenhalgh, C., Tennent, P., Chalmers, M. and Brown, B. (2006). Supporting ethnographic studies of ubiquitous computing in the wild. In Proc. DIS '06. 60- 69. ACM Press.}. The major advantage of mixed-reality games is the fact that they are situated in the real world, which arguably leads to increased efficacy of the behavioural observations when compared to computational simulations.\\

Now, in order to develop agent-based coordination algorithms that are fit to be trialled in real-world mixed-reality games, we note that none of the approaches discussed above (in Section \ref{sec:agentsdisasters}) take into account the underlying uncertainty of complex human activities. Hence, in this paper, we turn to decision-theoretic planning to handle such uncertainties. We discuss this framework and potential solution approaches next.

\subsection{Background on Decision-Theoretic Multi-Agent Planning}
Decision theoretic planning is typically solved using Markov Decision Processes \cite{xx}. A {\em Markov decision process} (MDP) is a mathematical framework for sequential decision making under uncertainty where the problem is specified as a set of states and transition functions (specifying links between these states based on the actions taken). Then, the solution to an MDP specifies what action should be taken in each state given the possible transitions from a given state. In the presence of multiple agents, this model has been extended to {\em multi-agent MDP} (MMDP)~\cite{boutilier1996planning} where the action chosen at any state consists of individual action components performed by the agents. Theoretically, any algorithm such as {\em linear programming}, {\em value iteration}, or {\em policy iteration} that can solve MDPs can also be used to solve MMDPs. However, these are likely to be very inefficient because the action space grows exponentially with the number of agents. In an attempt to combat this complexity, To \cite{boutilier2000stochastic} show how  domain structure can be exploited and  thus introduced the {\em factored MDP} (FMDP)~  in which the state space is described by a set of variables and the transition model is defined by a {\em dynamic Bayesian network} (DBN). When the agents can only observe partial
information about the state, this problem can be modelled by {\em multi-agent partially observable MDPs} (MPOMDP)~\cite{pynadath2002communicative}. Similar to MMDP, MPOMDP can be treated as an extension of single-agent POMDP to multi-agent domains. This analogy is useful because MPOMDPs can be solved as belief-state MMDPs where a belief state is a probability distribution over the states. All the above models assume that there is a centralised unit that will select a joint action for the team and distribute each action component to the corresponding agent. {\em Decentralised POMDP} (DEC-POMDP)~\cite{bernstein2002complexity} is a more general model where the agents are controlled in a decentralised manner. In other words, there is no centralised unit for distributing the actions and each agent must choose its own action based on the local observation.

In this paper, we restrict ourself to model our problem as the MMDP because other models do not fit the characteristic of our domain or are too difficult to be solved with the size of our problem. Specifically, in our domain, we consider a central controller (at headquarters) that will collect all the information and distribute the commands to each filed responder. Therefore, it is not necessary to assume that the information is only partial (as in MPOMDPs) or the decision must be made locally by the responders (as in DEC-POMDPs). Furthermore, those models are much harder than MMDPs and the existing algorithms can only solve very small problems. Moreover, we do not use the FMDP because most of the algorithms for solving this model as it requires that the value function can be factored additively into a set of localized value functions~\cite{koller2000policy,guestrin2001multiagent,guestrin2003efficient} and our problem does not have such structures. For example, in our domain, several tasks may depend on the same responder. If she is delayed in one task, this may affect the completion of the other tasks. In other words, the completion of one task may depend on the completion of the other tasks, and  so, the value function can not be factored on the basis of the local task states. Our settings are also different from the one in~\cite{Chapman2009} where they assume that the responders are self-interested and need to negotiate with each other on the task that they want to perform next.

As discussed above, any algorithm that can solve large MDPs can be used to solve MMDPs. However, most of the existing approaches are offline algorithms (see the most recent survey~\cite{kolobov2012planning} for more detail). The main disadvantage of offline algorithms is that they must compute a
complete action mapping for all possible states in the policy. This is intractable for problems with huge state space as in our domain. In contrast to offline approaches, online algorithms interleave planning with execution and only need to compute the best action for the current state instead of the entire state space. Specifically, we adopt the basic framework of {\em Monte-Carlo tree search} (MCTS)~\cite{kocsis2006bandit}, which is currently the
leading online planning algorithm for large MDPs, and divide our online algorithm into two levels: task planning and path planning. It is worth pointing out that our method is different from the hierarchical planning for MMDPs~\cite{musliner2006coordinated} because it requires the task hierarchy to be part of the model and our problem does not have such task hierarchy for the responders. Indeed, our problem is more closely related to the {\em coalition formation with spatial and temporal constraints} (CFST) problem where agents form coalitions to complete tasks, each with different demands. However, existing work on CFST often assumes that there is no uncertainty on the agents' actions and the environment~\cite{ramchurn:etal:2010}.

%
%
%\todo{
%The following are a few suggestions for improving the work.
%-- the paper should cite the work by Humphereys and Adams that discussed assignment of responders in emergency situations. Their work is particularly relevant because of the way they balanced competing task demands.
%}
