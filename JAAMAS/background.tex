\section{Background and Related Work}\label{sec:relatedwork}
In this section we discuss related work and provide a short background on the techniques used in this paper.  As our work lies at the intersection between Multi-Agent Coordination and Human-Computer Interaction (HCI) for disaster management applications, we discuss relevant algorithms for multi-agent coordination to support emergency responders and then describe the HCI techniques and approaches for the same purpose. We then go on to discuss the challenges relevant to human-agent collaboration and then justify our use of mixed-reality games to evaluate this form of collaboration.  Through our analysis we also identify the challenges that pertain to the coordination of human emergency responders under significant uncertainty and therefore, conclude with a survey on decision-theoretic approaches to solving the coordination problem under uncertainty in order to justify our agent-based solution for the team coordination problem.
\subsection{Human Team Coordination for Disaster Response}
Team coordination focuses on managing interdependencies between activities performed  by individual team members to achieve the team's goal \cite{Malone1990}. In emergency response situations, failures in team coordination can often occur due to the complexities of such interdependencies, and such failures are widely acknowledged as the most significant factor that can cost human lives \cite[p. 2]{Toups2011}. In particular, related work studies the challenges that arise when team members aim to create a \emph{shared understanding} (e.g., of what needs to be done) \cite{Convertino2011}, develop \emph{situation awareness} (i.e., knowledge of the environment and the actors within it) \cite{bader2008digital}, and \emph{align cooperative action} through on-going communication \cite{Toups2011}.

Moreover, we note the work of \cite{chen2005} that highlighted that a key characteristic of large-scale disasters is the presence of multiple, spatially distributed incidents. To deal with multiple incidents, the disaster response team has to coordinate spatially distributed resources and personnel to carry out operations (e.g., search, rescue, and evacuation). Therefore, it is necessary to optimise the coordination of teams by allocating tasks to teams in time and space efficiently and sufficiently. Given this, a number of tools and system architectures have been developed to support such team coordination \cite{Monares2011,Padilha2010,Convertino2011}. However, while these approaches focus on providing tools to human teams to better share  information and formulate plans,  they do not consider how such team coordination could be \emph{optimised} using agent-based planning. Hence, in the next section, we  survey a number of agent-based solutions to the task allocation problem in disaster response.

\subsection{Agent-Based Planning for Disaster Response}\label{sec:agentsdisasters}
Kitano et al \cite{kitano:2001} were the first to propose disaster response as a key application area for multi-agent systems. Since then, a number of algorithms and simulation platforms have been developed to solve the computational challenges involved. For example, algorithms  have been developed to efficiently allocate emergency responders to rescue tasks (e.g., to rescue civilians, extinguish fires, or unblock roads) for (i) decentralised coordination: where emergency responders need to choose their actions based on local knowledge \cite{Chapman2009,puyol:etal:2014}, (ii)  coordination by a central authority: where a command centre is able to choose actions (against potentially adversarial agents) for all the members of the team given complete knowledge of the system \cite{Khan-2011-JAAMAS,koes2006constraint,Scerri2005,tambe:etal:2011}, and (iii) coalition formation: where sub-teams can perform tasks with different levels of efficiency, as defined by the synergies between their capabilities (e.g., when two policemen help rescue a civilian from rubble they would be less effective than a fire and rescue officer and a medic) \cite{ramchurn:etal:2010}.   Similar to\cite{Khan-2011-JAAMAS,koes2006constraint,Scerri2005}, in our work, we  adopt a centralised approach to the coordination problem to  and additionally consider the uncertainty in the environment (see more details in Section \ref{sec:decisiontheoretic}).

Now, many of the above algorithms are actually evaluated in simulation using the  Robo\-Cup\-Rescue disaster simulation platform \cite{skinner:ramchurn:2010}. In this platform, emergency response tasks are modelled computationally (e.g., functions describing speed and efficiency of agents at completing tasks) and the emergency responders are modelled as agents that automatically implement the outputs of a given task allocation algorithm \cite{kleiner:etal:2013,ramchurn:etal:2010}. On a related note, \cite{nakajima:etal:2007} present a system to simulate evacuations during major disasters and show how human subjects using mobile phones can be influenced by the movement of artificial agents. However, they do not attempt to optimise the evacuation process.  While such evaluations are useful to determine extreme scenarios (e.g., best case when all agents implement all tasks perfectly or worst case when they do not), they are prone to misrepresentations of human decision making since they do not capture all the subtleties of human interactions and perception. In particular, they assume that all the actors in the system perfectly understand the messages exchanged, the information presented on their communication devices, and that they always follow the instructions received perfectly. In contrast, in a disaster response setting, responders may not  always understand the plans computed by an agent nor obey instructions they receive from an agent (e.g., if they are part of different agencies, misunderstand the instructions, or are just tired).  

\subsection{Challenges for Human Agent Collaboration}\label{sec:challenges}
Many multi-agent coordination algorithms have the potential to be applied to support task assignment of responder teams. However, before we use those algorithms to build agent-based planning support systems, there is a need to understand how humans and agents can effectively collaborate.  Controlled experiments designed by the Human Factors community have sought to identify key aspects of human-agent collaboration \cite{Bradshaw2011,Cooke2006,Sukthankar,Wagner2004}, propose transfer-of-control policies to shift control between humans and agents \cite{scerri:etal:2005},  and evaluate strategies of agent support for teams \cite{Lenox2000}. In particular, prior research has recognised that interaction design is vital for the performance of socio-technical human-agent systems \cite{Rachlin1997}, particularly where an agent directly instructs humans \cite{Moran2013}. In particular, the latter argue that, with inappropriate interaction design, agent-based planning support may function inefficiently, or at worst, hinder the performance of human teams.  This is echoed by \cite{Bowers1994} who have shown that an ill-designed work-flow management/automation system can lead to undesirable results, not only fail to improve work efficiency but also hinders human performance. Bowers et al. found that extreme difficulties might be encountered when introducing new technology support for human teams. Thus,  new technologies might not support, but  disrupt smooth workflow if they are designed in an organisationally unacceptable way \cite{Abbott1994}. In some cases, people not be able to access agent-based guidance simply because they do not wish to share their context with a centralised autonomous system \cite{Wirz10_HumanCom}.

Although there is much literature in planning support, task assignment, and human-agent collaboration, to the exception of \cite{scerri:etal:2003,schurr2005defacto}, no real world studies of how human emergency response teams  actually handle agent support  have been carried out.  In fact, \cite{scerri:etal:2003,schurr2005defacto} mainly focus on humans acting as peers to agents in computational simulations rather than real-world deployments in the field. This further highlights the need to evaluate these technologies with human users before they are deployed in real-world settings. In particular, in this work, we turn to the use of gamification to run such evaluations. 

Recent work by Tambe et al. \cite{tambe:etal:2011}  has shown how humans may be able to  implement plans computed as solutions to a Stackelberg game. While their solutions have been deployed with various human teams  (e.g., guards at LAX airport or security teams in the Boston/New York/LA harbours), they do not consider how such plans can be generated in real-time in collaboration with humans (i.e., internalising human input dynamically).


\subsection{Disaster Simulation and Games} \label{sec:simulationvgames}
Computational simulations, particularly agent-based simulations, are the predominant approach in the computing literature to predict the consequences of certain courses of action in disasters \cite{Hawe2012}, to model information flow among first responders \cite{Robinson},  to model the logistic distribution of emergency relief supplies \cite{Lee2009}. However, as hinted above, these simulations are a poor substitute for real-world field trials. For example, Simonovic highlights that simulations may rely on unrealistic geographical topography, and most importantly, may not ``account for human psychosocial characteristics and individual movement, and (...) learning ability" \cite{Simonovic2010}.  Moreover, the impact of emotional and physical responses likely in a disaster, such as stress, fear, exertion or panic \cite{Drury2009} remains absent in most approaches that rely purely on computational simulation.

To combat this, in our study, we adopt a serious mixed-reality game approach to provide a setting in which people experience realistic cognitive and physical stress \cite{Fischer}. Mixed-reality games are recreational experiences that make use of pervasive technologies such as smart phones, wireless technologies and sensors with the aim of blending game events into a real world environment  \cite{Benford2005a} . Arguably, they have become an established vehicle to explore socio-technical issues in complex real world settings \cite{Crabtree2006a}. The major advantage of mixed-reality games is the fact that they are situated in the real world, which  leads to increased efficacy of the behavioural observations when compared to computational simulations. 

By adopting the mixed reality games approach, for the first time, we are also able to run repeated trials of interfaces for humans to use to control and receive instructions from an agent in real-time. In our particular context, the planning agent works alongside a human commander at central command (who can visualise its outputs and override them) in order to instruct human players on the ground. This arrangement of humans being guided by an agent in collaboration with a supervisor is novel in itself and raises issues related to trust in the planner agent, delegation of control (to humans on the ground, to agent at headquarters, or to human at headquarters), and interaction design for human-agent systems that can support collaborative work in real-time settings.

\subsection{A Short Background on Decision-Theoretic Multi-Agent Planning}\label{sec:decisiontheoretic}
Decision theoretic planning is typically solved using Markov Decision Processes \cite{kolobov2012planning}. A {\em Markov decision process} (MDP) is a mathematical framework for sequential decision making under uncertainty where the problem is specified as a set of states and transition functions (specifying links between these states based on the actions taken). Then, the solution to an MDP specifies what action should be taken in each state given the possible transitions from a given state. In the presence of multiple agents, this model has been extended to {\em multi-agent MDP} (MMDP)~\cite{boutilier1996planning} where the action chosen at any state consists of individual action components performed by the agents. Theoretically, any algorithm such as {\em linear programming}, {\em value iteration}, or {\em policy iteration} that can solve MDPs can also be used to solve MMDPs. However, these are likely to be very inefficient because the action space grows exponentially with the number of agents. In an attempt to combat this complexity,  \cite{boutilier2000stochastic} show how  domain structure can be exploited and  thus introduced the {\em factored MDP} (FMDP)~  in which the state space is described by a set of variables and the transition model is defined by a {\em dynamic Bayesian network} (DBN). When the agents can only observe partial
information about the state, this problem can be modelled by {\em multi-agent partially observable MDPs} (MPOMDP)~\cite{pynadath2002communicative}. Similar to MMDP, MPOMDP can be treated as an extension of single-agent POMDP to multi-agent domains. This analogy is useful because MPOMDPs can be solved as belief-state MMDPs where a belief state is a probability distribution over the states. All the above models assume that there is a centralised unit that will select a joint action for the team and distribute each action component to the corresponding agent. {\em Decentralised POMDP} (DEC-POMDP)~\cite{bernstein2002complexity} is a more general model where the agents are controlled in a decentralised manner. In other words, there is no centralised unit for distributing the actions and each agent must choose its own action based on the local observation.

In this paper, we restrict ourself to model our problem as the MMDP because other models do not fit the characteristics of our domain or are too difficult to be solved with the size of our problem. Specifically, in our domain, we consider a central controller (at headquarters) that will collect all the information and distribute the commands to each field responder. Therefore, it is not necessary to assume that the information is only partial (as in MPOMDPs) or the decision must be made locally by the responders (as in DEC-POMDPs). Furthermore, those models are much harder than MMDPs and the existing algorithms can only solve very small problems. Moreover, we do not use the FMDP because most of the algorithms for solving this model require that the value function can be factored additively into a set of localized value functions~\cite{koller2000policy,guestrin2001multiagent,guestrin2003efficient} and our problem does not have such structures. For example, in our domain, several tasks may depend on the same responder. If she is delayed in one task, this may affect the completion of the other tasks. In other words, the completion of one task may depend on the completion of the other tasks, and  so, the value function can not be factored on the basis of the local task states. Our settings are also different from the one in~\cite{Chapman2009} where they assume that the responders are self-interested and need to negotiate with each other on the task that they want to perform next.

As discussed above, any algorithm that can solve large MDPs can be used to solve MMDPs. However, most of the existing approaches are offline algorithms (see the most recent survey~\cite{kolobov2012planning} for more detail). The main disadvantage of offline algorithms is that they must compute a
complete action mapping for all possible states in the policy. This is intractable for problems with huge state space as in our domain. In contrast to offline approaches, online algorithms interleave planning with execution and only need to compute the best action for the current state instead of the entire state space. Specifically, we adopt the basic framework of {\em Monte-Carlo tree search} (MCTS)~\cite{kocsis2006bandit}, which is currently the
leading online planning algorithm for large MDPs, and divide our online algorithm into two levels: task planning and path planning. It is worth pointing out that our method is different from the hierarchical planning for MMDPs~\cite{musliner2006coordinated} because it requires the task hierarchy to be part of the model and our problem does not have such task hierarchy for the responders. Indeed, our problem is more closely related to the {\em coalition formation with spatial and temporal constraints} (CFST) problem where agents form coalitions to complete tasks, each with different demands. However, existing work on CFST often assumes that there is no uncertainty on the agents' actions and the environment~\cite{ramchurn:etal:2010}.

%
%
%\todo{
%The following are a few suggestions for improving the work.
%-- the paper should cite the work by Humphereys and Adams that discussed assignment of responders in emergency situations. Their work is particularly relevant because of the way they balanced competing task demands.
%}
